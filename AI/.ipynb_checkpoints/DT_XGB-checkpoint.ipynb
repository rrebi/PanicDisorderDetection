{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf68788-2f3b-4bac-8981-5a7c8b74d519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTree\n",
      "Training set accuracy: 1.0000\n",
      "Validation set accuracy: 0.9889\n",
      "Training set error: 0.0000\n",
      "Validation set error: 0.0111\n",
      "\n",
      "Model: XGBoost\n",
      "Training set accuracy: 0.9983\n",
      "Validation set accuracy: 0.9900\n",
      "Training set error: 0.0017\n",
      "Validation set error: 0.0100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing, Cross-validate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load datasets\n",
    "df_train = pd.read_csv('panic_disorder_dataset_training.csv')\n",
    "df_test = pd.read_csv('panic_disorder_dataset_testing.csv')\n",
    "\n",
    "# Drop Participant ID from training and test data\n",
    "df_train = df_train.drop(columns=['Participant ID'])\n",
    "df_test = df_test.drop(columns=['Participant ID'])\n",
    "\n",
    "# Features and target\n",
    "X = df_train.drop(columns=['Panic Disorder Diagnosis'])\n",
    "y = df_train['Panic Disorder Diagnosis']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Impute missing values\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Apply imputation\n",
    "X_train[categorical_features] = imputer_cat.fit_transform(X_train[categorical_features])\n",
    "X_val[categorical_features] = imputer_cat.transform(X_val[categorical_features])\n",
    "X_train[numerical_features] = imputer_num.fit_transform(X_train[numerical_features])\n",
    "X_val[numerical_features] = imputer_num.transform(X_val[numerical_features])\n",
    "\n",
    "# Label encode categorical features\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_val[col] = le.transform(X_val[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the rest of the features as they are\n",
    ")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit the model on the training set and evaluate on the validation set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_score = pipeline.score(X_train, y_train)\n",
    "    val_score = pipeline.score(X_val, y_val)\n",
    "    \n",
    "    # Calculate training and validation errors\n",
    "    train_error = 1 - train_score\n",
    "    val_error = 1 - val_score\n",
    "    \n",
    "    # Print model performance\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Training set accuracy: {train_score:.4f}\")\n",
    "    print(f\"Validation set accuracy: {val_score:.4f}\")\n",
    "    print(f\"Training set error: {train_error:.4f}\")\n",
    "    print(f\"Validation set error: {val_error:.4f}\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca900961-39bf-446d-a5d1-cb92ac18dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Pruned Validation Accuracy: 0.9905\n",
      "Decision Tree Pruned Training Accuracy: 0.9913\n",
      "Decision Tree Pruned Training Error: 0.0087\n",
      "Decision Tree Pruned Validation Error: 0.0095\n"
     ]
    }
   ],
   "source": [
    "# Pruned Decision Tree model\n",
    "dt_model_pruned = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=20, min_samples_leaf=1)\n",
    "pipeline_dt_pruned = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', dt_model_pruned)\n",
    "])\n",
    "pipeline_dt_pruned.fit(X_train, y_train)\n",
    "dt_pruned_val_score = pipeline_dt_pruned.score(X_val, y_val)\n",
    "dt_pruned_train_score = pipeline_dt_pruned.score(X_train, y_train)\n",
    "dt_pruned_train_error = 1 - dt_pruned_train_score\n",
    "dt_pruned_val_error = 1 - dt_pruned_val_score\n",
    "\n",
    "print(f\"Decision Tree Pruned Validation Accuracy: {dt_pruned_val_score:.4f}\")\n",
    "print(f\"Decision Tree Pruned Training Accuracy: {dt_pruned_train_score:.4f}\")\n",
    "print(f\"Decision Tree Pruned Training Error: {dt_pruned_train_error:.4f}\")\n",
    "print(f\"Decision Tree Pruned Validation Error: {dt_pruned_val_error:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d9f877-f5e3-452b-866b-0a200da145f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Pruned Validation Accuracy: 0.9908\n",
      "Decision Tree Pruned Training Accuracy: 0.9929\n",
      "Decision Tree Pruned Training Error: 0.0071\n",
      "Decision Tree Pruned Validation Error: 0.0092\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'n_estimators': 353,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.07639730394446925,\n",
    "    'subsample': 0.9769972567915909,\n",
    "    'colsample_bytree': 0.8641799601859603,\n",
    "    'gamma': 0.05958068943077993,\n",
    "    'min_child_weight': 4\n",
    "}\n",
    "\n",
    "# Use the best parameters to create a model\n",
    "xgb_model_tuned = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, **best_params)\n",
    "\n",
    "# Create the pipeline with the best model\n",
    "pipeline_xgb_tuned = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_model_tuned)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the full training set\n",
    "pipeline_xgb_tuned.fit(X_train, y_train)\n",
    "\n",
    "xgb_tuned_val_score = pipeline_xgb_tuned.score(X_val, y_val)\n",
    "xgb_tuned_train_score = pipeline_xgb_tuned.score(X_train, y_train)\n",
    "xgb_tuned_train_error = 1 - xgb_tuned_train_score\n",
    "xgb_tuned_val_error = 1 - xgb_tuned_val_score\n",
    "\n",
    "print(f\"Decision Tree Pruned Validation Accuracy: {xgb_tuned_val_score:.4f}\")\n",
    "print(f\"Decision Tree Pruned Training Accuracy: {xgb_tuned_train_score:.4f}\")\n",
    "print(f\"Decision Tree Pruned Training Error: {xgb_tuned_train_error:.4f}\")\n",
    "print(f\"Decision Tree Pruned Validation Error: {xgb_tuned_val_error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da0e880-f037-4fa8-9df8-7b85f088838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Decision Tree Test Accuracy: 0.9907\n",
      "Pruned Decision Tree Test Error: 0.0093\n",
      "Tuned XGBoost Test Accuracy: 0.9911\n",
      "Tuned XGBoost Test Error: 0.0089\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.drop(columns=['Panic Disorder Diagnosis'])\n",
    "y_test = df_test['Panic Disorder Diagnosis']\n",
    "\n",
    "# Impute missing values for the test data\n",
    "X_test[categorical_features] = imputer_cat.transform(X_test[categorical_features])\n",
    "X_test[numerical_features] = imputer_num.transform(X_test[numerical_features])\n",
    "\n",
    "# Label encode categorical features for the test data\n",
    "for col in categorical_features:\n",
    "    le = label_encoders[col]\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "# Predict using the pruned Decision Tree model\n",
    "dt_pruned_test_predictions = pipeline_dt_pruned.predict(X_test)\n",
    "dt_pruned_test_accuracy = accuracy_score(y_test, dt_pruned_test_predictions)\n",
    "dt_pruned_test_error = 1 - dt_pruned_test_accuracy\n",
    "\n",
    "print(f\"Pruned Decision Tree Test Accuracy: {dt_pruned_test_accuracy:.4f}\")\n",
    "print(f\"Pruned Decision Tree Test Error: {dt_pruned_test_error:.4f}\")\n",
    "\n",
    "# Predict using the tuned XGBoost model\n",
    "xgb_tuned_test_predictions = pipeline_xgb_tuned.predict(X_test)\n",
    "xgb_tuned_test_accuracy = accuracy_score(y_test, xgb_tuned_test_predictions)\n",
    "xgb_tuned_test_error = 1 - xgb_tuned_test_accuracy\n",
    "\n",
    "print(f\"Tuned XGBoost Test Accuracy: {xgb_tuned_test_accuracy:.4f}\")\n",
    "print(f\"Tuned XGBoost Test Error: {xgb_tuned_test_error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e52d5c-279e-4a20-b413-98f7e40ce3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Save the pipeline and the label encoders to a pickle file\n",
    "with open('xgb_model.pkl', 'wb') as file:\n",
    "    pickle.dump((pipeline_xgb_tuned, label_encoders, imputer_cat, imputer_num), file)\n",
    "# Save the pipeline and the label encoders to a pickle file\n",
    "with open('dtc_model.pkl', 'wb') as file:\n",
    "    pickle.dump((pipeline_dt_pruned, label_encoders, imputer_cat, imputer_num), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d053c4-b8b0-4e37-8b31-2888ad4548fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the pruned Decision Tree pipeline\n",
    "with open('dt_pruned_pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(trpipeline_dt_pruned, file)\n",
    "\n",
    "# Save the tuned XGBoost pipeline\n",
    "with open('xgb_tuned_pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline_xgb_tuned, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
